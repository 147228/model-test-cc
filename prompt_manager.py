# -*- coding: utf-8 -*-
"""
æç¤ºè¯ç®¡ç†å™¨ - ç®¡ç†æµ‹è¯•ç”¨ä¾‹æç¤ºè¯
ç‰ˆæœ¬ 2.1 - å¢å¼ºç‰ˆï¼šé‡è¯•æœºåˆ¶ã€è¶…æ—¶æ—¥å¿—ã€tokensç»Ÿè®¡ã€ç¼“å­˜
"""

import json
import re
import time
import random
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any

try:
    import requests
except ImportError:
    requests = None


class PromptManager:
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3
    BASE_DELAY = 2
    MAX_DELAY = 30
    REQUEST_TIMEOUT = 1200  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self.text_cases_file = self.base_dir / "test_cases" / "text_cases.json"
        self.writing_cases_file = self.base_dir / "test_cases" / "writing_cases.json"
        self.image_cases_file = self.base_dir / "test_cases" / "image_cases.json"
        self.cache_file = self.base_dir / "test_cases" / "_prompt_cache.json"
        self.history_file = self.base_dir / "test_cases" / "_generation_history.json"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        (self.base_dir / "test_cases").mkdir(parents=True, exist_ok=True)

    def load_cases(self, test_type: str) -> Dict:
        """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        if test_type == "text":
            file_path = self.text_cases_file
        elif test_type == "writing":
            file_path = self.writing_cases_file
        else:
            file_path = self.image_cases_file

        if not file_path.exists():
            return {"meta": {}, "cases": []}

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ç¡®ä¿å¿…è¦çš„å­—æ®µå­˜åœ¨
                if "meta" not in data:
                    data["meta"] = {}
                if "cases" not in data:
                    data["cases"] = []
                return data
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶æ ¼å¼é”™è¯¯ {file_path}: {e}")
            return {"meta": {}, "cases": []}
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {file_path}: {e}")
            return {"meta": {}, "cases": []}

    def save_cases(self, test_type: str, data: Dict):
        """ä¿å­˜æµ‹è¯•ç”¨ä¾‹"""
        if test_type == "text":
            file_path = self.text_cases_file
        elif test_type == "writing":
            file_path = self.writing_cases_file
        else:
            file_path = self.image_cases_file

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # æ·»åŠ å…ƒæ•°æ®
        if "meta" not in data:
            data["meta"] = {}
        data["meta"]["last_updated"] = datetime.now().isoformat()
        data["meta"]["case_count"] = len(data.get("cases", []))

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•ä¿å­˜æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {file_path}: {e}")
            raise

    def add_case(self, test_type: str, case: Dict):
        """æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
        data = self.load_cases(test_type)

        # æ£€æŸ¥IDæ˜¯å¦å·²å­˜åœ¨
        existing_ids = [c["id"] for c in data["cases"]]
        if case["id"] in existing_ids:
            print(f"è­¦å‘Š: æ¡ˆä¾‹ID {case['id']} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–")
            data["cases"] = [c for c in data["cases"] if c["id"] != case["id"]]

        data["cases"].append(case)
        self.save_cases(test_type, data)

    def update_case(self, test_type: str, case_id: str, updated_case: Dict):
        """æ›´æ–°æµ‹è¯•ç”¨ä¾‹"""
        data = self.load_cases(test_type)
        found = False
        for i, case in enumerate(data["cases"]):
            if case["id"] == case_id:
                data["cases"][i] = updated_case
                found = True
                break

        if not found:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¡ˆä¾‹ID {case_id}")
            return False

        self.save_cases(test_type, data)
        return True

    def delete_case(self, test_type: str, case_id: str) -> bool:
        """åˆ é™¤æµ‹è¯•ç”¨ä¾‹"""
        data = self.load_cases(test_type)
        original_count = len(data["cases"])
        data["cases"] = [c for c in data["cases"] if c["id"] != case_id]

        if len(data["cases"]) == original_count:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¡ˆä¾‹ID {case_id}")
            return False

        self.save_cases(test_type, data)
        return True

    def _get_cache_key(self, test_type: str, count: int, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{test_type}_{count}_{model}"
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def _load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜"""
        if not self.cache_file.exists():
            return {}
        try:
            with open(self.cache_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {}

    def _save_cache(self, cache: Dict):
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•ä¿å­˜ç¼“å­˜: {e}")

    def _save_to_history(self, test_type: str, prompts: List[Dict], model: str,
                         token_usage: Dict, duration: float):
        """ä¿å­˜ç”Ÿæˆå†å²"""
        history = []
        if self.history_file.exists():
            try:
                with open(self.history_file, "r", encoding="utf-8") as f:
                    history = json.load(f)
            except:
                history = []

        history.append({
            "timestamp": datetime.now().isoformat(),
            "test_type": test_type,
            "model": model,
            "count": len(prompts),
            "token_usage": token_usage,
            "duration_seconds": round(duration, 2),
            "prompts": prompts
        })

        # åªä¿ç•™æœ€è¿‘50æ¡è®°å½•
        history = history[-50:]

        try:
            with open(self.history_file, "w", encoding="utf-8") as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•ä¿å­˜ç”Ÿæˆå†å²: {e}")

    def generate_prompts(self, api_url: str, api_key: str, model: str,
                        test_type: str, count: int, log_callback=None,
                        use_cache: bool = False) -> List[Dict]:
        """
        ä½¿ç”¨AIç”Ÿæˆæç¤ºè¯ï¼ˆå¸¦é‡è¯•å’Œç»Ÿè®¡ï¼‰

        Args:
            api_url: APIåœ°å€
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
            test_type: æµ‹è¯•ç±»å‹ ("text" æˆ– "image")
            count: ç”Ÿæˆæ•°é‡
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            ç”Ÿæˆçš„æç¤ºè¯åˆ—è¡¨
        """
        if requests is None:
            raise ImportError("éœ€è¦å®‰è£… requests åº“")

        log = log_callback or print

        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cache_key = self._get_cache_key(test_type, count, model)
            cache = self._load_cache()
            if cache_key in cache:
                cached = cache[cache_key]
                log(f"ä½¿ç”¨ç¼“å­˜çš„æç¤ºè¯ (ç”Ÿæˆäº {cached.get('timestamp', 'unknown')})")
                return cached.get("prompts", [])

        # æ„å»ºæç¤ºè¯
        if test_type == "text":
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIæµ‹è¯•ä¸“å®¶ã€‚è¯·ç”Ÿæˆ{count}ä¸ªç”¨äºæµ‹è¯•AIä»£ç ç”Ÿæˆèƒ½åŠ›çš„æç¤ºè¯ã€‚
æ¯ä¸ªæç¤ºè¯åº”è¯¥è¦æ±‚AIç”Ÿæˆä¸€ä¸ªå®Œæ•´å¯è¿è¡Œçš„HTMLæ–‡ä»¶ï¼ŒåŒ…å«CSSå’ŒJavaScriptã€‚
æ¡ˆä¾‹åº”è¯¥æ¶µç›–ä¸åŒéš¾åº¦å’Œç±»åˆ«ï¼Œå¦‚ï¼šåŠ¨ç”»æ•ˆæœã€äº¤äº’æ¸¸æˆã€æ•°æ®å¯è§†åŒ–ã€å®ç”¨å·¥å…·ç­‰ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "id": "T<åºå·>",
    "name": "æ¡ˆä¾‹åç§°",
    "category": "åˆ†ç±»",
    "difficulty": "ç®€å•|ä¸­|é«˜",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "icon": "emojiå›¾æ ‡",
    "prompt": "è¯¦ç»†çš„æµ‹è¯•æç¤ºè¯ï¼Œè¦æ±‚ç”Ÿæˆå•æ–‡ä»¶å®Œæ•´å¯è¿è¡Œçš„HTML..."
  }}
]
"""
        else:
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIæµ‹è¯•ä¸“å®¶ã€‚è¯·ç”Ÿæˆ{count}ä¸ªç”¨äºæµ‹è¯•AIå›¾åƒç”Ÿæˆèƒ½åŠ›çš„æç¤ºè¯ã€‚
æ¡ˆä¾‹åº”è¯¥æ¶µç›–ä¸åŒåœºæ™¯å’Œé£æ ¼ï¼Œå¦‚ï¼šæœªæ¥ç§‘æŠ€ã€è‡ªç„¶åœºæ™¯ã€äººç‰©è‚–åƒã€å»ºç­‘è®¾è®¡ã€äº§å“è®¾è®¡ç­‰ã€‚
æç¤ºè¯åº”è¯¥ä½¿ç”¨è‹±æ–‡ï¼Œè¯¦ç»†æè¿°ç”»é¢å†…å®¹ã€é£æ ¼ã€å…‰å½±ç­‰ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "id": "I<åºå·>",
    "name": "æ¡ˆä¾‹åç§°",
    "category": "åˆ†ç±»",
    "difficulty": "ç®€å•|ä¸­|é«˜",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "icon": "emojiå›¾æ ‡",
    "prompt": "Detailed English prompt for image generation..."
  }}
]
"""

        log(f"æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆ{count}ä¸ª{test_type}æç¤ºè¯...")
        log(f"ä½¿ç”¨æ¨¡å‹: {model}")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": model,
            "messages": [{"role": "user", "content": system_prompt}],
            "max_tokens": 4096
        }

        endpoint = f"{api_url.rstrip('/')}/chat/completions"
        start_time = time.time()
        token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

        for attempt in range(self.MAX_RETRIES + 1):
            attempt_start = time.time()
            try:
                log(f"    å¼€å§‹è¯·æ±‚ (ç¬¬{attempt + 1}æ¬¡å°è¯•)...")

                response = requests.post(
                    endpoint,
                    json=payload,
                    headers=headers,
                    timeout=self.REQUEST_TIMEOUT
                )

                attempt_duration = time.time() - attempt_start
                log(f"    è¯·æ±‚å®Œæˆï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")

                response.raise_for_status()
                response_json = response.json()

                # æå–tokenä½¿ç”¨é‡
                if "usage" in response_json:
                    usage = response_json["usage"]
                    token_usage = {
                        "prompt_tokens": usage.get("prompt_tokens", 0),
                        "completion_tokens": usage.get("completion_tokens", 0),
                        "total_tokens": usage.get("total_tokens", 0)
                    }
                    log(f"    Tokens: è¾“å…¥={token_usage['prompt_tokens']}, è¾“å‡º={token_usage['completion_tokens']}, æ€»è®¡={token_usage['total_tokens']}")

                # æå–å†…å®¹
                content = ""
                try:
                    content = response_json["choices"][0]["message"]["content"]
                except (KeyError, IndexError, TypeError) as e:
                    log(f"    å“åº”æ ¼å¼å¼‚å¸¸: {e}")
                    raise Exception(f"å“åº”æ ¼å¼å¼‚å¸¸: {e}")

                # æå–JSON
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    try:
                        prompts = json.loads(json_match.group())
                        total_duration = time.time() - start_time
                        log(f"æˆåŠŸç”Ÿæˆ{len(prompts)}ä¸ªæç¤ºè¯ï¼Œæ€»è€—æ—¶ {total_duration:.1f}ç§’")

                        # ä¿å­˜åˆ°å†å²è®°å½•
                        self._save_to_history(test_type, prompts, model, token_usage, total_duration)

                        # ä¿å­˜åˆ°ç¼“å­˜
                        if use_cache:
                            cache = self._load_cache()
                            cache_key = self._get_cache_key(test_type, count, model)
                            cache[cache_key] = {
                                "timestamp": datetime.now().isoformat(),
                                "prompts": prompts,
                                "token_usage": token_usage
                            }
                            self._save_cache(cache)

                        return prompts
                    except json.JSONDecodeError as e:
                        log(f"    JSONè§£æå¤±è´¥: {e}")
                        raise Exception(f"JSONè§£æå¤±è´¥: {e}")
                else:
                    log("    æ— æ³•ä»å“åº”ä¸­æå–JSONæ•°ç»„")
                    # ä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
                    debug_file = self.base_dir / "test_cases" / f"_debug_response_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                    with open(debug_file, "w", encoding="utf-8") as f:
                        f.write(content)
                    log(f"    åŸå§‹å“åº”å·²ä¿å­˜åˆ° {debug_file.name}")
                    raise Exception("æ— æ³•ä»å“åº”ä¸­æå–JSONæ•°ç»„")

            except requests.exceptions.Timeout as e:
                attempt_duration = time.time() - attempt_start
                log(f"    â° è¯·æ±‚è¶…æ—¶! å·²ç­‰å¾… {attempt_duration:.1f}ç§’ (è¶…æ—¶é™åˆ¶: {self.REQUEST_TIMEOUT}ç§’)")

            except requests.exceptions.ConnectionError as e:
                log(f"    ğŸ”Œ è¿æ¥é”™è¯¯: {str(e)[:100]}")

            except requests.exceptions.HTTPError as e:
                status_code = response.status_code if 'response' in locals() else 'unknown'
                if isinstance(status_code, int) and status_code in [429, 500, 502, 503, 504]:
                    log(f"    ğŸš« HTTP {status_code} é”™è¯¯")
                else:
                    log(f"    âŒ HTTPé”™è¯¯: {e}")
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: HTTP {status_code}")

            except Exception as e:
                if attempt == self.MAX_RETRIES:
                    log(f"ç”Ÿæˆæç¤ºè¯å¤±è´¥: {str(e)}")
                    return []

            # é‡è¯•é€»è¾‘
            if attempt < self.MAX_RETRIES:
                delay = min(self.BASE_DELAY * (2 ** attempt) + random.uniform(0, 1), self.MAX_DELAY)
                log(f"    ğŸ”„ ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯•...")
                time.sleep(delay)

        log(f"ç”Ÿæˆæç¤ºè¯å¤±è´¥ï¼ˆå·²é‡è¯•{self.MAX_RETRIES}æ¬¡ï¼‰")
        return []

    def get_next_id(self, test_type: str) -> str:
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨ID"""
        data = self.load_cases(test_type)

        # ç¡®å®šå‰ç¼€
        if test_type == "text":
            prefix = "T"
        elif test_type == "writing":
            prefix = "W"
        else:
            prefix = "I"

        if not data["cases"]:
            return f"{prefix}01"

        # æå–æ‰€æœ‰IDçš„æ•°å­—éƒ¨åˆ†
        ids = []
        for c in data["cases"]:
            case_id = c.get("id", "")
            if case_id.startswith(prefix) and case_id[1:].isdigit():
                ids.append(int(case_id[1:]))

        if not ids:
            return f"{prefix}01"

        next_num = max(ids) + 1
        return f"{prefix}{next_num:02d}"

    def get_generation_history(self, limit: int = 10) -> List[Dict]:
        """è·å–ç”Ÿæˆå†å²"""
        if not self.history_file.exists():
            return []
        try:
            with open(self.history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
                return history[-limit:]
        except:
            return []

    def get_stats(self) -> Dict:
        """è·å–æç¤ºè¯ç»Ÿè®¡ä¿¡æ¯"""
        text_data = self.load_cases("text")
        writing_data = self.load_cases("writing")
        image_data = self.load_cases("image")

        return {
            "text_count": len(text_data.get("cases", [])),
            "writing_count": len(writing_data.get("cases", [])),
            "image_count": len(image_data.get("cases", [])),
            "text_last_updated": text_data.get("meta", {}).get("last_updated"),
            "writing_last_updated": writing_data.get("meta", {}).get("last_updated"),
            "image_last_updated": image_data.get("meta", {}).get("last_updated"),
            "total_count": len(text_data.get("cases", [])) + len(writing_data.get("cases", [])) + len(image_data.get("cases", []))
        }
