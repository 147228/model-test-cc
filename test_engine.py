# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¼•æ“ - æ‰§è¡Œä»£ç ç”Ÿæˆã€æ–‡ç”Ÿæ–‡å’Œæ–‡ç”Ÿå›¾æµ‹è¯•ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
ç‰ˆæœ¬ 2.2 - å¢å¼ºç‰ˆï¼šæ”¯æŒä»£ç ç”Ÿæˆã€å†™ä½œèƒ½åŠ›ã€æ–‡ç”Ÿå›¾ä¸‰ç±»æµ‹è¯„
"""

import json
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import base64
import re
import time
import random
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import wraps
from dataclasses import dataclass, field, asdict
from typing import Optional, Dict, List, Any


def sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    # Windowså’ŒLinuxéƒ½ä¸å…è®¸çš„å­—ç¬¦
    invalid_chars = r'<>:"/\|?*'
    # ä¸­æ–‡æ‹¬å·è½¬è‹±æ–‡æ‹¬å·
    name = name.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
    # æ›¿æ¢éæ³•å­—ç¬¦ä¸ºä¸‹åˆ’çº¿
    for char in invalid_chars:
        name = name.replace(char, '_')
    # å»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
    name = name.strip(' .')
    # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    if len(name) > 100:
        name = name[:100]
    return name


@dataclass
class TokenUsage:
    """Tokenä½¿ç”¨ç»Ÿè®¡"""
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0

    def add(self, other: 'TokenUsage'):
        self.prompt_tokens += other.prompt_tokens
        self.completion_tokens += other.completion_tokens
        self.total_tokens += other.total_tokens


@dataclass
class TestStats:
    """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
    total_cases: int = 0
    success_count: int = 0
    failed_count: int = 0
    html_extracted_count: int = 0
    no_html_count: int = 0
    total_tokens: TokenUsage = field(default_factory=TokenUsage)
    total_time_seconds: float = 0.0  # å¤šçº¿ç¨‹æ€»è€—æ—¶ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰
    sum_case_time_seconds: float = 0.0  # å•caseè€—æ—¶æ€»å’Œï¼ˆçœŸå®ç´¯è®¡æ—¶é—´ï¼‰
    avg_time_per_case: float = 0.0  # å•caseå¹³å‡è€—æ—¶
    avg_output_tokens_per_case: float = 0.0  # å•caseå¹³å‡è¾“å‡ºtokens
    avg_tokens_per_second: float = 0.0  # å¹³å‡è¾“å‡ºé€Ÿç‡ (tokens/s)
    timeout_count: int = 0
    retry_count: int = 0
    incomplete_count: int = 0  # è¾“å‡ºä¸å®Œæ•´æ¬¡æ•°

    def to_dict(self) -> Dict:
        return {
            "total_cases": self.total_cases,
            "success_count": self.success_count,
            "failed_count": self.failed_count,
            "html_extracted_count": self.html_extracted_count,
            "no_html_count": self.no_html_count,
            "total_tokens": asdict(self.total_tokens),
            "total_time_seconds": round(self.total_time_seconds, 2),
            "sum_case_time_seconds": round(self.sum_case_time_seconds, 2),
            "avg_time_per_case": round(self.avg_time_per_case, 2),
            "avg_output_tokens_per_case": round(self.avg_output_tokens_per_case, 2),
            "avg_tokens_per_second": round(self.avg_tokens_per_second, 2),
            "timeout_count": self.timeout_count,
            "retry_count": self.retry_count,
            "incomplete_count": self.incomplete_count
        }


class TestEngine:
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3
    BASE_DELAY = 2
    MAX_DELAY = 30
    REQUEST_TIMEOUT = 1200  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    # ä¸å®Œæ•´å“åº”æ£€æµ‹é…ç½®
    INCOMPLETE_RETRY_MAX = 2  # ä¸å®Œæ•´å“åº”æœ€å¤§é‡è¯•æ¬¡æ•°
    CONTINUE_CONVERSATION_MAX = 3  # è¿ç»­å¯¹è¯æœ€å¤§è½®æ•°ï¼ˆç”¨äºç»­å†™è¢«æˆªæ–­çš„å†…å®¹ï¼‰

    def __init__(self, api_url, api_key, text_model, image_model,
                 max_threads, output_dir, log_callback=None, progress_callback=None,
                 enable_thinking=False, max_tokens=None):
        """
        åˆå§‹åŒ–æµ‹è¯•å¼•æ“

        Args:
            api_url: APIåœ°å€
            api_key: APIå¯†é’¥
            text_model: æ–‡ç”Ÿæ–‡æ¨¡å‹
            image_model: æ–‡ç”Ÿå›¾æ¨¡å‹
            max_threads: æœ€å¤§çº¿ç¨‹æ•°
            output_dir: è¾“å‡ºç›®å½•
            log_callback: æ—¥å¿—å›è°ƒ
            progress_callback: è¿›åº¦å›è°ƒ
            enable_thinking: æ˜¯å¦å¯ç”¨thinkingæ¨¡å¼ï¼ˆå…¼å®¹DeepSeekç­‰æ”¯æŒæ€ç»´é“¾çš„æ¨¡å‹ï¼‰
            max_tokens: æœ€å¤§è¾“å‡ºtokensï¼Œé»˜è®¤Noneè¡¨ç¤ºä½¿ç”¨æœ€å¤§å€¼
        """
        self.api_url = api_url.rstrip("/")
        self.api_key = api_key
        self.text_model = text_model
        self.image_model = image_model
        self.max_threads = max_threads
        self.output_dir = Path(output_dir)
        self.log = log_callback or print
        self.update_progress = progress_callback or (lambda x: None)

        # thinkingæ¨¡å¼é…ç½®
        self.enable_thinking = enable_thinking
        # max_tokensï¼šé»˜è®¤è®¾ç½®ä¸ºè¾ƒå¤§å€¼ï¼Œå…¼å®¹å„å®¶API
        self.max_tokens = max_tokens if max_tokens else 16384  # é»˜è®¤16Kï¼Œå¯é…ç½®

        self.is_running = True
        self.results = {"text": [], "image": [], "writing": []}

        # ç»Ÿè®¡ä¿¡æ¯
        self.text_stats = TestStats()
        self.image_stats = TestStats()
        self.writing_stats = TestStats()
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None

        # åˆ›å»ºå¸¦æœ‰è‡ªåŠ¨é‡è¯•æœºåˆ¶çš„HTTP Session
        self.session = self._create_robust_session()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        (self.output_dir / "text").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "image").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "writing").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "website").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "logs").mkdir(parents=True, exist_ok=True)

    def _create_robust_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦æœ‰è‡ªåŠ¨é‡è¯•å’Œè¿æ¥æ± çš„HTTP Session"""
        session = requests.Session()

        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,  # æ€»é‡è¯•æ¬¡æ•°
            backoff_factor=1,  # é€€é¿å› å­ï¼š1, 2, 4ç§’
            status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è¯•çš„çŠ¶æ€ç 
            allowed_methods=["POST"],  # å…è®¸é‡è¯•çš„æ–¹æ³•
            raise_on_status=False  # ä¸è‡ªåŠ¨æŠ›å‡ºå¼‚å¸¸ï¼Œè®©æˆ‘ä»¬æ‰‹åŠ¨å¤„ç†
        )

        # é…ç½®HTTPé€‚é…å™¨
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=10,  # è¿æ¥æ± å¤§å°
            pool_maxsize=20,  # æœ€å¤§è¿æ¥æ•°
            pool_block=False
        )

        session.mount("http://", adapter)
        session.mount("https://", adapter)

        return session

    def stop(self):
        """åœæ­¢æµ‹è¯•"""
        self.is_running = False

    def get_stats_summary(self) -> Dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        total_time = self.end_time - self.start_time if self.end_time and self.start_time else 0
        return {
            "text_stats": self.text_stats.to_dict(),
            "image_stats": self.image_stats.to_dict(),
            "total_time_seconds": round(total_time, 2),
            "total_tokens": {
                "prompt_tokens": self.text_stats.total_tokens.prompt_tokens + self.image_stats.total_tokens.prompt_tokens,
                "completion_tokens": self.text_stats.total_tokens.completion_tokens + self.image_stats.total_tokens.completion_tokens,
                "total_tokens": self.text_stats.total_tokens.total_tokens + self.image_stats.total_tokens.total_tokens
            }
        }

    def load_test_cases(self, test_type):
        """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        base_dir = Path(__file__).parent
        if test_type == "text":
            case_file = base_dir / "test_cases" / "text_cases.json"
        elif test_type == "writing":
            case_file = base_dir / "test_cases" / "writing_cases.json"
        else:
            case_file = base_dir / "test_cases" / "image_cases.json"

        if not case_file.exists():
            self.log(f"è­¦å‘Š: æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ä¸å­˜åœ¨ {case_file}")
            return []

        with open(case_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("cases", [])

    def call_api_with_retry(self, prompt, model, is_image=False, case_id="") -> Dict[str, Any]:
        """
        è°ƒç”¨APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰ï¼Œè‡ªåŠ¨å…¼å®¹æµå¼å’Œéæµå¼å“åº”

        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°
            is_image: æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆ
            case_id: æ¡ˆä¾‹IDï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            åŒ…å«å“åº”å†…å®¹ã€tokenä½¿ç”¨é‡ã€è€—æ—¶ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        # é¦–å…ˆå°è¯•æµå¼å“åº”
        try:
            return self._call_api_streaming(prompt, model, is_image, case_id)
        except Exception as e:
            error_str = str(e).lower()
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ‡æ¢åˆ°éæµå¼æ¨¡å¼
            # 1. å¦‚æœæ˜ç¡®æç¤ºä¸æ”¯æŒæµå¼
            # 2. å¦‚æœæ˜¯SSEç›¸å…³é”™è¯¯
            # 3. å¦‚æœå·²ç»é‡è¯•å¤šæ¬¡ä»ç„¶å¤±è´¥
            should_try_non_stream = any([
                "stream" in error_str and "not" in error_str,
                "sse" in error_str,
                "event-stream" in error_str,
                "chunk" in error_str and "invalid" in error_str,
                "å·²é‡è¯•" in error_str  # å·²ç»å¤šæ¬¡é‡è¯•å¤±è´¥
            ])

            if should_try_non_stream:
                self.log(f"    ğŸ’¡ [{case_id}] æ£€æµ‹åˆ°æµå¼å“åº”ä¸å…¼å®¹ï¼Œå°è¯•éæµå¼æ¨¡å¼...")
                try:
                    return self._call_api_non_streaming(prompt, model, is_image, case_id)
                except Exception as non_stream_error:
                    # å¦‚æœéæµå¼ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºæ›´è¯¦ç»†çš„é”™è¯¯
                    raise Exception(f"æµå¼å’Œéæµå¼å“åº”å‡å¤±è´¥ã€‚æµå¼é”™è¯¯: {str(e)[:100]}; éæµå¼é”™è¯¯: {str(non_stream_error)[:100]}")
            else:
                # å¦‚æœä¸æ˜¯æµå¼ç›¸å…³é—®é¢˜ï¼Œç›´æ¥æŠ›å‡ºåŸå§‹é”™è¯¯
                raise

    def _call_api_streaming(self, prompt, model, is_image=False, case_id="") -> Dict[str, Any]:
        """æµå¼APIè°ƒç”¨ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "Expect": "",  # ç¦ç”¨100-continue
            "Connection": "keep-alive",
            "Accept": "text/event-stream"  # SSEæµå¼å“åº”
        }

        # æ„å»ºpayloadï¼Œå…¼å®¹OpenAIæ ¼å¼
        # å¯¹äºæ¨ç†æ¨¡å‹ä½¿ç”¨æµå¼å“åº”ï¼Œé¿å…ä¸­è½¬æœåŠ¡è¶…æ—¶
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": self.max_tokens,
            "stream": True  # å¯ç”¨æµå¼å“åº”ï¼Œé¿å…Response ended prematurely
        }

        # æ·»åŠ thinkingæ¨¡å¼æ”¯æŒï¼ˆå…¼å®¹å¤šç§æ ¼å¼ï¼‰
        if self.enable_thinking:
            # æ–¹å¼1: DeepSeek V3.2é£æ ¼
            payload["enable_thinking"] = True
            # æ–¹å¼2: ä¹Ÿå¯ä»¥é€šè¿‡extra_bodyä¼ é€’ï¼ˆæŸäº›SDKéœ€è¦ï¼‰
            # è¿™é‡Œç›´æ¥åœ¨payloadä¸­æ·»åŠ ï¼Œå…¼å®¹æ›´å¤šæƒ…å†µ

        endpoint = f"{self.api_url}/chat/completions"
        last_exception = None
        total_retry_count = 0
        incomplete_retry_count = 0
        request_start_time = time.time()

        for attempt in range(self.MAX_RETRIES + 1):
            if not self.is_running:
                raise Exception("æµ‹è¯•å·²åœæ­¢")

            attempt_start_time = time.time()
            response = None

            try:
                self.log(f"    [{case_id}] å¼€å§‹è¯·æ±‚ (ç¬¬{attempt + 1}æ¬¡å°è¯•)...")

                # ä½¿ç”¨æµå¼å“åº”é¿å…ä¸­è½¬æœåŠ¡è¶…æ—¶
                response = self.session.post(
                    endpoint,
                    json=payload,
                    headers=headers,
                    timeout=(30, self.REQUEST_TIMEOUT),
                    stream=True
                )

                response.raise_for_status()

                # æ˜¾å¼è®¾ç½®ç¼–ç ä¸ºUTF-8 (ä¿®å¤Windowsä¹±ç é—®é¢˜)
                response.encoding = 'utf-8'

                # æ”¶é›†SSEæµå¼å“åº”æ•°æ®
                collected_content = ""
                collected_reasoning = ""
                token_usage = TokenUsage()
                finish_reason = None

                for line in response.iter_lines(decode_unicode=True):
                    if not self.is_running:
                        raise Exception("æµ‹è¯•å·²åœæ­¢")

                    if not line:
                        continue

                    # SSEæ ¼å¼: data: {...}
                    if line.startswith("data: "):
                        data_str = line[6:]  # å»æ‰ "data: " å‰ç¼€

                        if data_str.strip() == "[DONE]":
                            break

                        try:
                            chunk = json.loads(data_str)

                            # æå–deltaå†…å®¹
                            if "choices" in chunk and len(chunk["choices"]) > 0:
                                delta = chunk["choices"][0].get("delta", {})

                                # æ”¶é›†content
                                if "content" in delta and delta["content"]:
                                    collected_content += delta["content"]

                                # æ”¶é›†reasoning_content (DeepSeekæ¨ç†æ¨¡å‹)
                                if "reasoning_content" in delta and delta["reasoning_content"]:
                                    collected_reasoning += delta["reasoning_content"]

                                # è·å–finish_reason
                                if chunk["choices"][0].get("finish_reason"):
                                    finish_reason = chunk["choices"][0]["finish_reason"]

                            # æå–usage (æŸäº›APIåœ¨æœ€åä¸€ä¸ªchunkè¿”å›)
                            if "usage" in chunk and chunk["usage"]:
                                usage = chunk["usage"]
                                token_usage.prompt_tokens = usage.get("prompt_tokens", 0)
                                token_usage.completion_tokens = usage.get("completion_tokens", 0)
                                token_usage.total_tokens = usage.get("total_tokens", 0)

                        except json.JSONDecodeError:
                            continue

                attempt_duration = time.time() - attempt_start_time
                self.log(f"    [{case_id}] è¯·æ±‚å®Œæˆï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")

                # å¦‚æœcontentä¸ºç©ºä½†reasoning_contentæœ‰å†…å®¹ï¼Œä½¿ç”¨reasoning_content
                if not collected_content and collected_reasoning:
                    collected_content = collected_reasoning
                    self.log(f"    ğŸ“ [{case_id}] ä½¿ç”¨reasoning_contentä½œä¸ºå“åº”å†…å®¹")

                # æ„å»ºå…¼å®¹çš„response_jsonæ ¼å¼
                response_json = {
                    "choices": [{
                        "message": {
                            "content": collected_content,
                            "reasoning_content": collected_reasoning if collected_reasoning else None
                        },
                        "finish_reason": finish_reason
                    }],
                    "usage": {
                        "prompt_tokens": token_usage.prompt_tokens,
                        "completion_tokens": token_usage.completion_tokens,
                        "total_tokens": token_usage.total_tokens
                    }
                }

                # å¦‚æœæ²¡æœ‰ä»æµä¸­è·å–åˆ°usageï¼Œä¼°ç®—tokens
                if token_usage.total_tokens == 0:
                    # ç²—ç•¥ä¼°ç®—ï¼š4ä¸ªå­—ç¬¦çº¦ç­‰äº1ä¸ªtoken
                    estimated_completion = len(collected_content + collected_reasoning) // 4
                    token_usage.completion_tokens = estimated_completion
                    token_usage.total_tokens = estimated_completion
                    self.log(f"    [{case_id}] Tokens (ä¼°ç®—): è¾“å‡ºâ‰ˆ{estimated_completion}")
                else:
                    self.log(f"    [{case_id}] Tokens: è¾“å…¥={token_usage.prompt_tokens}, è¾“å‡º={token_usage.completion_tokens}, æ€»è®¡={token_usage.total_tokens}")

                # æ£€æŸ¥å“åº”å®Œæ•´æ€§ï¼ˆfinish_reasonï¼‰
                is_incomplete = False
                if finish_reason == "length":
                    is_incomplete = True
                    self.log(f"    âš ï¸ [{case_id}] è¾“å‡ºè¾¾åˆ°max_tokensä¸Šé™è¢«æˆªæ–­ (finish_reason=length)")
                    self.log(f"    ğŸ’¡ [{case_id}] æç¤º: æˆªæ–­æ— æ³•é€šè¿‡é‡è¯•è§£å†³ï¼Œå°†æ£€æŸ¥HTMLæ˜¯å¦å·²å®Œæ•´")

                # è®¡ç®—è¾“å‡ºé€Ÿç‡
                tokens_per_second = 0.0
                if attempt_duration > 0 and token_usage.completion_tokens > 0:
                    tokens_per_second = token_usage.completion_tokens / attempt_duration
                    self.log(f"    [{case_id}] è¾“å‡ºé€Ÿç‡: {tokens_per_second:.1f} tokens/s")

                # æ³¨æ„: ä¸å¯¹lengthæˆªæ–­è¿›è¡Œé‡è¯•ï¼Œå› ä¸ºé‡è¯•ä¸èƒ½è§£å†³max_tokensé™åˆ¶é—®é¢˜
                # åç»­ä¼šåœ¨HTMLæå–æ—¶æ£€æµ‹å†…å®¹æ˜¯å¦å®Œæ•´

                total_duration = time.time() - request_start_time
                return {
                    "response": response_json,
                    "token_usage": token_usage,
                    "duration_seconds": round(total_duration, 2),
                    "retry_count": total_retry_count,
                    "incomplete_retry_count": incomplete_retry_count,
                    "is_incomplete": is_incomplete,
                    "finish_reason": finish_reason,
                    "tokens_per_second": round(tokens_per_second, 2),
                    "success": True
                }

            except requests.exceptions.Timeout as e:
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"è¯·æ±‚è¶…æ—¶ ({self.REQUEST_TIMEOUT}ç§’): {str(e)}")
                self.log(f"    â° [{case_id}] è¯·æ±‚è¶…æ—¶! å·²ç­‰å¾… {attempt_duration:.1f}ç§’ (è¶…æ—¶é™åˆ¶: {self.REQUEST_TIMEOUT}ç§’)")

            except requests.exceptions.ChunkedEncodingError as e:
                # å¤„ç† "Response ended prematurely" é”™è¯¯
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"å“åº”ä¼ è¾“ä¸­æ–­: {str(e)}")
                self.log(f"    ğŸ“¡ [{case_id}] å“åº”ä¼ è¾“ä¸­æ–­ (Response ended prematurely)ï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")
                self.log(f"    ğŸ’¡ [{case_id}] è¿™é€šå¸¸æ˜¯æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜å¯¼è‡´çš„ï¼Œå°†å¢åŠ å»¶è¿Ÿåé‡è¯•")

            except requests.exceptions.ConnectionError as e:
                attempt_duration = time.time() - attempt_start_time
                error_str = str(e)
                # æ£€æµ‹æ˜¯å¦æ˜¯ Response ended prematurely ç±»å‹çš„é”™è¯¯
                if "ended prematurely" in error_str.lower() or "incomplete" in error_str.lower():
                    last_exception = Exception(f"å“åº”ä¼ è¾“ä¸­æ–­: {error_str}")
                    self.log(f"    ğŸ“¡ [{case_id}] å“åº”ä¼ è¾“ä¸­æ–­ï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")
                else:
                    last_exception = Exception(f"è¿æ¥é”™è¯¯: {error_str}")
                    self.log(f"    ğŸ”Œ [{case_id}] è¿æ¥é”™è¯¯ï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’: {error_str[:100]}")

            except requests.exceptions.HTTPError as e:
                attempt_duration = time.time() - attempt_start_time
                status_code = response.status_code if response is not None else 'unknown'

                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                if isinstance(status_code, int) and status_code in [429, 500, 502, 503, 504]:
                    error_messages = {
                        429: "è¯·æ±‚è¿‡äºé¢‘ç¹",
                        500: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                        502: "ç½‘å…³é”™è¯¯",
                        503: "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                        504: "ç½‘å…³è¶…æ—¶"
                    }
                    error_desc = error_messages.get(status_code, "HTTPé”™è¯¯")
                    last_exception = Exception(f"HTTP {status_code} ({error_desc}): {str(e)}")
                    self.log(f"    ğŸš« [{case_id}] HTTP {status_code} ({error_desc})ï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")
                else:
                    # ä¸å¯é‡è¯•çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: HTTP {status_code} - {str(e)}")

            except json.JSONDecodeError as e:
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"å“åº”JSONè§£æå¤±è´¥: {str(e)}")
                self.log(f"    âŒ [{case_id}] å“åº”JSONè§£æå¤±è´¥: {str(e)[:100]}")
                # å¦‚æœèƒ½è·å–åˆ°å“åº”æ–‡æœ¬ï¼Œè®°å½•ä¸‹æ¥ä¾¿äºè°ƒè¯•
                if response is not None:
                    try:
                        raw_text = response.text[:500] if response.text else "ç©ºå“åº”"
                        self.log(f"    ğŸ“‹ [{case_id}] åŸå§‹å“åº”: {raw_text}")
                    except:
                        pass

            except Exception as e:
                attempt_duration = time.time() - attempt_start_time
                error_str = str(e)
                # æ£€æµ‹å¸¸è§çš„ç½‘ç»œä¸­æ–­é”™è¯¯
                if any(keyword in error_str.lower() for keyword in ["prematurely", "incomplete", "broken pipe", "reset by peer"]):
                    last_exception = Exception(f"ç½‘ç»œä¼ è¾“ä¸­æ–­: {error_str}")
                    self.log(f"    ğŸ“¡ [{case_id}] ç½‘ç»œä¼ è¾“ä¸­æ–­ï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’: {error_str[:100]}")
                else:
                    last_exception = Exception(f"æœªçŸ¥é”™è¯¯: {error_str}")
                    self.log(f"    âŒ [{case_id}] æœªçŸ¥é”™è¯¯: {error_str[:100]}")

            # é‡è¯•é€»è¾‘ - å¢åŠ å»¶è¿Ÿæ—¶é—´
            if attempt < self.MAX_RETRIES:
                total_retry_count += 1
                # ä½¿ç”¨æ›´é•¿çš„åŸºç¡€å»¶è¿Ÿï¼Œç‰¹åˆ«æ˜¯å¯¹äºç½‘ç»œä¸­æ–­é”™è¯¯
                base_delay = self.BASE_DELAY * 2 if "ä¼ è¾“ä¸­æ–­" in str(last_exception) or "prematurely" in str(last_exception).lower() else self.BASE_DELAY
                delay = min(base_delay * (2 ** attempt) + random.uniform(0, 2), self.MAX_DELAY)
                self.log(f"    ğŸ”„ [{case_id}] ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• (å‰©ä½™{self.MAX_RETRIES - attempt}æ¬¡)...")
                time.sleep(delay)

        total_duration = time.time() - request_start_time
        # è®°å½•å¤±è´¥æ—¥å¿—åˆ°æ–‡ä»¶
        self._log_failure(case_id, prompt, model, last_exception, total_duration)
        raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{self.MAX_RETRIES}æ¬¡ï¼Œæ€»è€—æ—¶{total_duration:.1f}ç§’ï¼‰: {str(last_exception)}")

    def _call_api_non_streaming(self, prompt, model, is_image=False, case_id="") -> Dict[str, Any]:
        """éæµå¼APIè°ƒç”¨ï¼ˆå…¼å®¹æ›´å¤šæ¨¡å‹ï¼‰"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "Accept": "application/json"
        }

        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": self.max_tokens,
            "stream": False  # éæµå¼å“åº”
        }

        # å¯é€‰ï¼šæ·»åŠ thinkingæ¨¡å¼ï¼ˆæŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒï¼‰
        if self.enable_thinking:
            payload["enable_thinking"] = True

        endpoint = f"{self.api_url}/chat/completions"
        last_exception = None
        total_retry_count = 0
        request_start_time = time.time()

        for attempt in range(self.MAX_RETRIES + 1):
            if not self.is_running:
                raise Exception("æµ‹è¯•å·²åœæ­¢")

            attempt_start_time = time.time()
            response = None

            try:
                self.log(f"    [{case_id}] å¼€å§‹éæµå¼è¯·æ±‚ (ç¬¬{attempt + 1}æ¬¡å°è¯•)...")

                response = self.session.post(
                    endpoint,
                    json=payload,
                    headers=headers,
                    timeout=(30, self.REQUEST_TIMEOUT)
                )

                response.raise_for_status()

                # æ˜¾å¼è®¾ç½®ç¼–ç ä¸ºUTF-8 (ä¿®å¤Windowsä¹±ç é—®é¢˜)
                response.encoding = 'utf-8'

                attempt_duration = time.time() - attempt_start_time
                self.log(f"    [{case_id}] è¯·æ±‚å®Œæˆï¼Œè€—æ—¶ {attempt_duration:.1f}ç§’")

                # è§£æJSONå“åº”
                response_json = response.json()

                # å…¼å®¹å¤šç§å“åº”æ ¼å¼
                content = ""
                reasoning_content = ""
                finish_reason = None
                token_usage = TokenUsage()

                # æå–choiceså’Œmessage
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    choice = response_json["choices"][0]

                    # æå–messageå†…å®¹
                    message = choice.get("message", {})
                    content = message.get("content", "")
                    reasoning_content = message.get("reasoning_content", "")

                    # æå–finish_reason
                    finish_reason = choice.get("finish_reason")

                # å¦‚æœcontentä¸ºç©ºä½†reasoning_contentæœ‰å†…å®¹ï¼Œä½¿ç”¨reasoning_content
                if not content and reasoning_content:
                    content = reasoning_content
                    self.log(f"    ğŸ“ [{case_id}] ä½¿ç”¨reasoning_contentä½œä¸ºå“åº”å†…å®¹")

                # æå–usage
                if "usage" in response_json:
                    usage = response_json["usage"]
                    token_usage.prompt_tokens = usage.get("prompt_tokens", 0)
                    token_usage.completion_tokens = usage.get("completion_tokens", 0)
                    token_usage.total_tokens = usage.get("total_tokens", 0)

                # å¦‚æœæ²¡æœ‰usageä¿¡æ¯ï¼Œä¼°ç®—tokens
                if token_usage.total_tokens == 0:
                    estimated_completion = len(content + reasoning_content) // 4
                    token_usage.completion_tokens = estimated_completion
                    token_usage.total_tokens = estimated_completion
                    self.log(f"    [{case_id}] Tokens (ä¼°ç®—): è¾“å‡ºâ‰ˆ{estimated_completion}")
                else:
                    self.log(f"    [{case_id}] Tokens: è¾“å…¥={token_usage.prompt_tokens}, è¾“å‡º={token_usage.completion_tokens}, æ€»è®¡={token_usage.total_tokens}")

                # æ£€æŸ¥å“åº”å®Œæ•´æ€§
                is_incomplete = False
                if finish_reason == "length":
                    is_incomplete = True
                    self.log(f"    âš ï¸ [{case_id}] è¾“å‡ºè¾¾åˆ°max_tokensä¸Šé™è¢«æˆªæ–­")

                # è®¡ç®—è¾“å‡ºé€Ÿç‡
                tokens_per_second = 0.0
                if attempt_duration > 0 and token_usage.completion_tokens > 0:
                    tokens_per_second = token_usage.completion_tokens / attempt_duration
                    self.log(f"    [{case_id}] è¾“å‡ºé€Ÿç‡: {tokens_per_second:.1f} tokens/s")

                total_duration = time.time() - request_start_time
                return {
                    "response": response_json,
                    "token_usage": token_usage,
                    "duration_seconds": round(total_duration, 2),
                    "retry_count": total_retry_count,
                    "incomplete_retry_count": 0,
                    "is_incomplete": is_incomplete,
                    "finish_reason": finish_reason,
                    "tokens_per_second": round(tokens_per_second, 2),
                    "success": True
                }

            except requests.exceptions.Timeout as e:
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"è¯·æ±‚è¶…æ—¶: {str(e)}")
                self.log(f"    â° [{case_id}] è¯·æ±‚è¶…æ—¶! å·²ç­‰å¾… {attempt_duration:.1f}ç§’")

            except requests.exceptions.HTTPError as e:
                attempt_duration = time.time() - attempt_start_time
                status_code = response.status_code if response is not None else 'unknown'

                # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                error_body = ""
                try:
                    if response is not None and response.text:
                        error_body = response.text[:500]
                        self.log(f"    ğŸ“‹ [{case_id}] é”™è¯¯å“åº”: {error_body}")
                except:
                    pass

                # å¯é‡è¯•çš„é”™è¯¯
                if isinstance(status_code, int) and status_code in [429, 500, 502, 503, 504]:
                    error_messages = {
                        429: "è¯·æ±‚è¿‡äºé¢‘ç¹",
                        500: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                        502: "ç½‘å…³é”™è¯¯",
                        503: "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                        504: "ç½‘å…³è¶…æ—¶"
                    }
                    error_desc = error_messages.get(status_code, "HTTPé”™è¯¯")
                    last_exception = Exception(f"HTTP {status_code} ({error_desc}): {str(e)}")
                    self.log(f"    ğŸš« [{case_id}] HTTP {status_code} ({error_desc})")
                else:
                    # ä¸å¯é‡è¯•çš„é”™è¯¯
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: HTTP {status_code} - {error_body if error_body else str(e)}")

            except json.JSONDecodeError as e:
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"å“åº”JSONè§£æå¤±è´¥: {str(e)}")
                self.log(f"    âŒ [{case_id}] å“åº”JSONè§£æå¤±è´¥")
                if response is not None:
                    try:
                        raw_text = response.text[:500] if response.text else "ç©ºå“åº”"
                        self.log(f"    ğŸ“‹ [{case_id}] åŸå§‹å“åº”: {raw_text}")
                    except:
                        pass

            except Exception as e:
                attempt_duration = time.time() - attempt_start_time
                last_exception = Exception(f"æœªçŸ¥é”™è¯¯: {str(e)}")
                self.log(f"    âŒ [{case_id}] æœªçŸ¥é”™è¯¯: {str(e)[:100]}")

            # é‡è¯•é€»è¾‘
            if attempt < self.MAX_RETRIES:
                total_retry_count += 1
                delay = min(self.BASE_DELAY * (2 ** attempt) + random.uniform(0, 2), self.MAX_DELAY)
                self.log(f"    ğŸ”„ [{case_id}] ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯•...")
                time.sleep(delay)

        total_duration = time.time() - request_start_time
        # è®°å½•å¤±è´¥æ—¥å¿—åˆ°æ–‡ä»¶
        self._log_failure(case_id, prompt, model, last_exception, total_duration)
        raise Exception(f"éæµå¼APIè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{self.MAX_RETRIES}æ¬¡ï¼Œæ€»è€—æ—¶{total_duration:.1f}ç§’ï¼‰: {str(last_exception)}")

    def _log_failure(self, case_id, prompt, model, exception, duration):
        """è®°å½•å¤±è´¥æ—¥å¿—åˆ°æ–‡ä»¶"""
        try:
            log_dir = self.output_dir / "logs"
            log_dir.mkdir(parents=True, exist_ok=True)

            log_file = log_dir / f"failures_{datetime.now().strftime('%Y%m%d')}.log"

            with open(log_file, "a", encoding="utf-8") as f:
                f.write(f"\n{'='*80}\n")
                f.write(f"æ—¶é—´: {datetime.now().isoformat()}\n")
                f.write(f"æ¡ˆä¾‹ID: {case_id}\n")
                f.write(f"æ¨¡å‹: {model}\n")
                f.write(f"è€—æ—¶: {duration:.1f}ç§’\n")
                f.write(f"é”™è¯¯: {str(exception)}\n")
                f.write(f"æç¤ºè¯å‰100å­—: {prompt[:100]}...\n")
                f.write(f"{'='*80}\n")
        except Exception as e:
            self.log(f"    âš ï¸ å†™å…¥å¤±è´¥æ—¥å¿—å¤±è´¥: {str(e)}")

    def continue_conversation(self, messages: List[Dict], model: str, case_id: str = "") -> Dict[str, Any]:
        """
        è¿ç»­å¯¹è¯ - ç”¨äºç»­å†™è¢«æˆªæ–­çš„å†…å®¹ï¼ˆå¸¦é‡è¯•ï¼‰

        Args:
            messages: å¯¹è¯å†å²
            model: æ¨¡å‹åç§°
            case_id: æ¡ˆä¾‹IDï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            åŒ…å«å“åº”å†…å®¹ã€tokenä½¿ç”¨é‡ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "Expect": "",
            "Connection": "keep-alive",
            "Accept": "text/event-stream"
        }

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": self.max_tokens,
            "stream": True  # å¯ç”¨æµå¼å“åº”
        }

        if self.enable_thinking:
            payload["enable_thinking"] = True

        endpoint = f"{self.api_url}/chat/completions"

        # ç»­å†™è¯·æ±‚ä¹Ÿæ”¯æŒé‡è¯•
        max_retries = 2
        for attempt in range(max_retries + 1):
            try:
                self.log(f"    ğŸ”„ [{case_id}] å‘é€ç»­å†™è¯·æ±‚ (ç¬¬{attempt + 1}æ¬¡)...")
                start_time = time.time()

                response = self.session.post(
                    endpoint,
                    json=payload,
                    headers=headers,
                    timeout=(30, self.REQUEST_TIMEOUT),
                    stream=True
                )

                response.raise_for_status()

                # æ˜¾å¼è®¾ç½®ç¼–ç ä¸ºUTF-8 (ä¿®å¤Windowsä¹±ç é—®é¢˜)
                response.encoding = 'utf-8'

                # æ”¶é›†SSEæµå¼å“åº”æ•°æ®
                collected_content = ""
                token_usage = TokenUsage()
                finish_reason = None

                for line in response.iter_lines(decode_unicode=True):
                    if not line:
                        continue

                    if line.startswith("data: "):
                        data_str = line[6:]

                        if data_str.strip() == "[DONE]":
                            break

                        try:
                            chunk = json.loads(data_str)

                            if "choices" in chunk and len(chunk["choices"]) > 0:
                                delta = chunk["choices"][0].get("delta", {})

                                if "content" in delta and delta["content"]:
                                    collected_content += delta["content"]

                                if "reasoning_content" in delta and delta["reasoning_content"]:
                                    collected_content += delta["reasoning_content"]

                                if chunk["choices"][0].get("finish_reason"):
                                    finish_reason = chunk["choices"][0]["finish_reason"]

                            if "usage" in chunk and chunk["usage"]:
                                usage = chunk["usage"]
                                token_usage.prompt_tokens = usage.get("prompt_tokens", 0)
                                token_usage.completion_tokens = usage.get("completion_tokens", 0)
                                token_usage.total_tokens = usage.get("total_tokens", 0)

                        except json.JSONDecodeError:
                            continue

                duration = time.time() - start_time
                self.log(f"    ğŸ”„ [{case_id}] ç»­å†™å®Œæˆï¼Œè€—æ—¶ {duration:.1f}ç§’ï¼Œè¾“å‡º {token_usage.completion_tokens} tokens")

                return {
                    "content": collected_content,
                    "token_usage": token_usage,
                    "duration_seconds": round(duration, 2),
                    "finish_reason": finish_reason,
                    "success": True
                }

            except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError) as e:
                error_str = str(e)
                if attempt < max_retries:
                    delay = (attempt + 1) * 5  # 5, 10ç§’
                    self.log(f"    ğŸ“¡ [{case_id}] ç»­å†™ä¼ è¾“ä¸­æ–­ï¼Œ{delay}ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    self.log(f"    âŒ [{case_id}] ç»­å†™è¯·æ±‚å¤±è´¥: {error_str[:100]}")
                    return {
                        "content": "",
                        "token_usage": TokenUsage(),
                        "duration_seconds": 0,
                        "finish_reason": "error",
                        "success": False
                    }

            except Exception as e:
                self.log(f"    âŒ [{case_id}] ç»­å†™è¯·æ±‚å¤±è´¥: {str(e)[:100]}")
                return {
                    "content": "",
                    "token_usage": TokenUsage(),
                    "duration_seconds": 0,
                    "finish_reason": "error",
                    "success": False
                }

        return {
            "content": "",
            "token_usage": TokenUsage(),
            "duration_seconds": 0,
            "finish_reason": "error",
            "success": False
        }

    def run_text_tests(self):
        """æ‰§è¡Œä»£ç ç”Ÿæˆæµ‹è¯•"""
        cases = self.load_test_cases("text")
        if not cases:
            self.log("æœªæ‰¾åˆ°ä»£ç ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
            return []

        self.log(f"å¼€å§‹ä»£ç ç”Ÿæˆæµ‹è¯•ï¼Œå…± {len(cases)} ä¸ªæ¡ˆä¾‹ï¼Œä½¿ç”¨æ¨¡å‹: {self.text_model}")
        self.text_stats = TestStats()
        self.text_stats.total_cases = len(cases)
        test_start_time = time.time()
        results = []

        # è®°å½•å¤±è´¥çš„æ¡ˆä¾‹ï¼Œç”¨äºæœ€åç»Ÿè®¡
        failed_cases = []

        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            futures = {}
            for case in cases:
                if not self.is_running:
                    break
                future = executor.submit(self.run_single_text_test, case)
                futures[future] = case

            for i, future in enumerate(as_completed(futures)):
                if not self.is_running:
                    break
                case = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                    self.text_stats.success_count += 1

                    # ç»Ÿè®¡tokens
                    if "token_usage" in result:
                        self.text_stats.total_tokens.add(result["token_usage"])

                    # ç´¯åŠ å•caseå®é™…è€—æ—¶ï¼ˆç”¨äºè®¡ç®—çœŸå®å¹³å‡å€¼ï¼‰
                    case_duration = result.get("duration_seconds", 0)
                    self.text_stats.sum_case_time_seconds += case_duration

                    # ç»Ÿè®¡HTMLæå–æƒ…å†µ
                    if result.get("html_file"):
                        self.text_stats.html_extracted_count += 1
                    elif result.get("txt_file"):
                        self.text_stats.no_html_count += 1

                    # ç»Ÿè®¡é‡è¯•æ¬¡æ•°
                    self.text_stats.retry_count += result.get("retry_count", 0)

                    # ç»Ÿè®¡ä¸å®Œæ•´å“åº”
                    if result.get("is_incomplete"):
                        self.text_stats.incomplete_count += 1

                    self.log(f"âœ… [ä»£ç ç”Ÿæˆ] {case['id']} {case['name']} - æˆåŠŸ (è€—æ—¶{case_duration}ç§’, {result.get('tokens_per_second', 0):.1f} tok/s)")
                except Exception as e:
                    error_msg = str(e)
                    self.text_stats.failed_count += 1

                    # æ£€æµ‹æ˜¯å¦ä¸ºè¶…æ—¶é”™è¯¯
                    if "è¶…æ—¶" in error_msg or "timeout" in error_msg.lower():
                        self.text_stats.timeout_count += 1

                    self.log(f"âŒ [ä»£ç ç”Ÿæˆ] {case['id']} {case['name']} - å¤±è´¥: {error_msg}")
                    failed_result = {
                        "id": case["id"],
                        "name": case["name"],
                        "category": case.get("category", "æœªåˆ†ç±»"),
                        "difficulty": case.get("difficulty", "ä¸­"),
                        "tags": case.get("tags", []),
                        "icon": case.get("icon", "ğŸ“„"),
                        "prompt": case["prompt"],
                        "success": False,
                        "error": error_msg,
                        "timestamp": datetime.now().isoformat()
                    }
                    results.append(failed_result)
                    failed_cases.append(case)

                progress = (i + 1) / len(cases) * 50
                self.update_progress(progress)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.text_stats.total_time_seconds = time.time() - test_start_time
        if self.text_stats.success_count > 0:
            # ä½¿ç”¨å•caseå®é™…è€—æ—¶æ€»å’Œè®¡ç®—å¹³å‡å€¼ï¼ˆæ­£ç¡®åæ˜ å•caseèƒ½åŠ›ï¼‰
            self.text_stats.avg_time_per_case = self.text_stats.sum_case_time_seconds / self.text_stats.success_count
            # è®¡ç®—å¹³å‡è¾“å‡ºtokens
            self.text_stats.avg_output_tokens_per_case = self.text_stats.total_tokens.completion_tokens / self.text_stats.success_count
            # è®¡ç®—å¹³å‡è¾“å‡ºé€Ÿç‡
            if self.text_stats.sum_case_time_seconds > 0:
                self.text_stats.avg_tokens_per_second = self.text_stats.total_tokens.completion_tokens / self.text_stats.sum_case_time_seconds

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        self.log(f"ğŸ“Š ä»£ç ç”Ÿæˆæµ‹è¯•å®Œæˆ:")
        self.log(f"    æˆåŠŸ: {self.text_stats.success_count}/{self.text_stats.total_cases}")
        self.log(f"    HTMLæå–: {self.text_stats.html_extracted_count}, æœªæå–: {self.text_stats.no_html_count}")
        self.log(f"    æ€»Tokens: {self.text_stats.total_tokens.total_tokens} (è¾“å…¥: {self.text_stats.total_tokens.prompt_tokens}, è¾“å‡º: {self.text_stats.total_tokens.completion_tokens})")
        self.log(f"    å¤šçº¿ç¨‹æ€»è€—æ—¶: {self.text_stats.total_time_seconds:.1f}ç§’")
        self.log(f"    å•caseå¹³å‡è€—æ—¶: {self.text_stats.avg_time_per_case:.1f}ç§’ (åŸºäº{self.text_stats.success_count}ä¸ªæˆåŠŸæ¡ˆä¾‹)")
        self.log(f"    å•caseå¹³å‡è¾“å‡º: {self.text_stats.avg_output_tokens_per_case:.0f} tokens")
        self.log(f"    å¹³å‡è¾“å‡ºé€Ÿç‡: {self.text_stats.avg_tokens_per_second:.1f} tokens/s")
        if self.text_stats.timeout_count > 0:
            self.log(f"    â° è¶…æ—¶æ¬¡æ•°: {self.text_stats.timeout_count}")
        if self.text_stats.retry_count > 0:
            self.log(f"    ğŸ”„ é‡è¯•æ¬¡æ•°: {self.text_stats.retry_count}")
        if self.text_stats.incomplete_count > 0:
            self.log(f"    âš ï¸ ä¸å®Œæ•´å“åº”: {self.text_stats.incomplete_count}")

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = self.output_dir / "text" / "_stats.json"
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(self.text_stats.to_dict(), f, ensure_ascii=False, indent=2)

        self.results["text"] = results
        return results

    def run_single_text_test(self, case) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªä»£ç ç”Ÿæˆæµ‹è¯•ï¼ˆå¸¦é‡è¯•ï¼‰"""
        api_result = self.call_api_with_retry(
            case["prompt"],
            self.text_model,
            is_image=False,
            case_id=case["id"]
        )

        response_json = api_result["response"]
        token_usage = api_result["token_usage"]
        duration_seconds = api_result["duration_seconds"]
        retry_count = api_result["retry_count"]
        tokens_per_second = api_result.get("tokens_per_second", 0)
        is_incomplete = api_result.get("is_incomplete", False)
        finish_reason = api_result.get("finish_reason", "")

        # å®‰å…¨æå–å†…å®¹ - æ”¯æŒå¤šç§å“åº”æ ¼å¼
        content = ""
        reasoning_content = ""
        raw_response = ""

        try:
            message = response_json.get("choices", [{}])[0].get("message", {})

            # å°è¯•è·å–å¸¸è§„content
            content = message.get("content") or ""

            # å°è¯•è·å–reasoning_content (deepseek-reasonerç­‰æ¨ç†æ¨¡å‹)
            reasoning_content = message.get("reasoning_content") or ""

            # å¦‚æœcontentä¸ºç©ºä½†reasoning_contentæœ‰å†…å®¹ï¼Œä½¿ç”¨reasoning_content
            if not content and reasoning_content:
                content = reasoning_content
                self.log(f"    ğŸ“ [{case['id']}] ä½¿ç”¨reasoning_contentä½œä¸ºå“åº”å†…å®¹")

            # å¦‚æœä¸¤è€…éƒ½ä¸ºç©ºï¼Œä¿å­˜å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
            if not content and not reasoning_content:
                raw_response = json.dumps(response_json, ensure_ascii=False, indent=2)
                self.log(f"    âš ï¸ [{case['id']}] contentå’Œreasoning_contentå‡ä¸ºç©ºï¼Œä¿å­˜åŸå§‹å“åº”")
                content = raw_response

        except (KeyError, IndexError, TypeError) as e:
            self.log(f"    âš ï¸ [{case['id']}] å“åº”æ ¼å¼å¼‚å¸¸: {str(e)}")
            # ä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
            raw_response = json.dumps(response_json, ensure_ascii=False, indent=2)
            content = raw_response

        # ä¿å­˜å“åº”ï¼ˆæ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼‰
        safe_name = sanitize_filename(case['name'])
        output_file = self.output_dir / "text" / f"{case['id']}_{safe_name}.json"
        result = {
            "id": case["id"],
            "name": case["name"],
            "category": case.get("category", "æœªåˆ†ç±»"),
            "difficulty": case.get("difficulty", "ä¸­"),
            "tags": case.get("tags", []),
            "icon": case.get("icon", "ğŸ“„"),
            "prompt": case["prompt"],
            "response": content,
            "reasoning_content": reasoning_content if reasoning_content else None,
            "timestamp": datetime.now().isoformat(),
            "success": True,
            # æ–°å¢å­—æ®µ
            "token_usage": asdict(token_usage),
            "duration_seconds": duration_seconds,
            "retry_count": retry_count,
            "tokens_per_second": tokens_per_second,
            "is_incomplete": is_incomplete,
            "finish_reason": finish_reason,
            "model": self.text_model
        }

        # å¦‚æœæœ‰åŸå§‹å“åº”ï¼ˆè¯´æ˜è§£æå¼‚å¸¸ï¼‰ï¼Œä¹Ÿä¿å­˜
        if raw_response:
            result["raw_response"] = raw_response

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # æå–HTML
        html_content, html_is_complete = self.extract_html(content)

        # å¦‚æœHTMLä¸å®Œæ•´ï¼Œå°è¯•ä½¿ç”¨è¿ç»­å¯¹è¯ç»­å†™
        if html_content and not html_is_complete and is_incomplete:
            self.log(f"    ğŸ”„ [{case['id']}] HTMLä¸å®Œæ•´ï¼Œå°è¯•è¿ç»­å¯¹è¯ç»­å†™...")

            # æ„å»ºå¯¹è¯å†å²
            messages = [
                {"role": "user", "content": case["prompt"]},
                {"role": "assistant", "content": content},
                {"role": "user", "content": "è¯·ç»§ç»­è¾“å‡ºï¼Œä»ä¸Šæ¬¡æˆªæ–­çš„åœ°æ–¹ç»§ç»­ï¼Œä¸è¦é‡å¤å·²è¾“å‡ºçš„å†…å®¹ï¼Œç›´æ¥è¾“å‡ºå‰©ä½™çš„ä»£ç éƒ¨åˆ†ã€‚"}
            ]

            combined_content = content
            total_continuation_tokens = TokenUsage()
            total_continuation_time = 0

            for round_num in range(self.CONTINUE_CONVERSATION_MAX):
                if not self.is_running:
                    break

                continuation = self.continue_conversation(messages, self.text_model, case["id"])

                if not continuation["success"] or not continuation["content"]:
                    self.log(f"    âš ï¸ [{case['id']}] ç¬¬{round_num + 1}è½®ç»­å†™å¤±è´¥æˆ–æ— å†…å®¹")
                    break

                # ç´¯åŠ ç»­å†™å†…å®¹
                combined_content += "\n" + continuation["content"]
                total_continuation_tokens.add(continuation["token_usage"])
                total_continuation_time += continuation["duration_seconds"]

                # æ›´æ–°å¯¹è¯å†å²
                messages.append({"role": "assistant", "content": continuation["content"]})
                messages.append({"role": "user", "content": "è¯·ç»§ç»­è¾“å‡ºï¼Œä»ä¸Šæ¬¡æˆªæ–­çš„åœ°æ–¹ç»§ç»­ã€‚"})

                # æ£€æŸ¥æ˜¯å¦å·²å®Œæ•´
                _, new_html_is_complete = self.extract_html(combined_content)
                if new_html_is_complete:
                    self.log(f"    âœ… [{case['id']}] ç»è¿‡{round_num + 1}è½®ç»­å†™ï¼ŒHTMLå·²å®Œæ•´")
                    html_content, html_is_complete = self.extract_html(combined_content)
                    # æ›´æ–°ç»Ÿè®¡
                    token_usage.add(total_continuation_tokens)
                    duration_seconds += total_continuation_time
                    result["response"] = combined_content
                    result["continuation_rounds"] = round_num + 1
                    break

                # å¦‚æœè¿™è½®ç»­å†™ä¹Ÿè¢«æˆªæ–­äº†ï¼Œç»§ç»­ä¸‹ä¸€è½®
                if continuation["finish_reason"] == "length":
                    self.log(f"    ğŸ”„ [{case['id']}] ç¬¬{round_num + 1}è½®ç»­å†™ä»è¢«æˆªæ–­ï¼Œç»§ç»­...")
                else:
                    # å¦‚æœä¸æ˜¯å› ä¸ºlengthæˆªæ–­ï¼Œå¯èƒ½æ˜¯æ­£å¸¸ç»“æŸä½†æ²¡æœ‰å®Œæ•´çš„HTML
                    self.log(f"    âš ï¸ [{case['id']}] ç¬¬{round_num + 1}è½®ç»­å†™ç»“æŸ (finish_reason={continuation['finish_reason']})")
                    break

            # æœ€ç»ˆå†æ¬¡æå–HTML
            html_content, html_is_complete = self.extract_html(combined_content)

        if html_content:
            html_file = self.output_dir / "text" / f"{case['id']}_{safe_name}.html"
            with open(html_file, "w", encoding="utf-8") as f:
                f.write(html_content)
            result["html_file"] = str(html_file)
            result["html_complete"] = html_is_complete

            # å¦‚æœAPIè¿”å›äº†æˆªæ–­æ ‡è®°ä½†HTMLå®é™…ä¸Šæ˜¯å®Œæ•´çš„ï¼Œæ›´æ–°çŠ¶æ€
            if is_incomplete and html_is_complete:
                result["is_incomplete"] = False
                self.log(f"    âœ… [{case['id']}] HTMLå·²å®Œæ•´æå–")
            elif not html_is_complete:
                result["is_incomplete"] = True
                self.log(f"    âš ï¸ [{case['id']}] HTMLä»ä¸å®Œæ•´ï¼ˆç¼ºå°‘</html>ç»“æŸæ ‡ç­¾ï¼‰")
        else:
            # å¦‚æœæ²¡æœ‰æå–åˆ°HTMLï¼Œä¿å­˜åŸå§‹å“åº”åˆ°txtæ–‡ä»¶
            txt_file = self.output_dir / "text" / f"{case['id']}_{safe_name}_raw.txt"
            with open(txt_file, "w", encoding="utf-8") as f:
                f.write(content if content else raw_response if raw_response else "å“åº”ä¸ºç©º")
            result["txt_file"] = str(txt_file)
            result["html_extracted"] = False
            self.log(f"    âš ï¸ [{case['id']}] æœªèƒ½æå–HTMLï¼ŒåŸå§‹å“åº”å·²ä¿å­˜åˆ° {txt_file.name}")

        # è¿”å›token_usageå¯¹è±¡ä¾›ç»Ÿè®¡ä½¿ç”¨
        result["token_usage"] = token_usage
        return result

    def extract_html(self, content):
        """
        ä»å“åº”ä¸­æå–HTMLä»£ç 

        Returns:
            tuple: (html_content, is_complete)
                   html_content: æå–çš„HTMLå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºNone
                   is_complete: HTMLæ˜¯å¦å®Œæ•´ï¼ˆä»¥</html>ç»“å°¾ï¼‰
        """
        # é¦–å…ˆå°è¯•åŒ¹é…å®Œæ•´çš„HTML
        patterns_complete = [
            r'```html\n(.*?</html>)\s*\n```',
            r'```\n(<!DOCTYPE html>.*?</html>)\s*\n```',
            r'(<!DOCTYPE html>.*?</html>)',
        ]

        for pattern in patterns_complete:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                html = match.group(1).strip()
                return html, True  # å®Œæ•´çš„HTML

        # å¦‚æœæ²¡æœ‰å®Œæ•´çš„HTMLï¼Œå°è¯•æå–å¯èƒ½è¢«æˆªæ–­çš„HTML
        patterns_partial = [
            r'```html\n(<!DOCTYPE html>.*?)(?:\n```|$)',  # ä»£ç å—ä¸­çš„HTMLï¼Œå¯èƒ½æ²¡æœ‰ç»“æŸæ ‡ç­¾
            r'```html\n(<html.*?)(?:\n```|$)',
            r'(<!DOCTYPE html>.*?)$',  # ä»å¼€å¤´åˆ°ç»“å°¾
        ]

        for pattern in patterns_partial:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                html = match.group(1).strip()
                # æ£€æŸ¥æ˜¯å¦ä»¥</html>ç»“å°¾
                is_complete = html.lower().rstrip().endswith('</html>')
                return html, is_complete

        return None, False

    def run_image_tests(self):
        """æ‰§è¡Œæ–‡ç”Ÿå›¾æµ‹è¯•"""
        cases = self.load_test_cases("image")
        if not cases:
            self.log("æœªæ‰¾åˆ°æ–‡ç”Ÿå›¾æµ‹è¯•ç”¨ä¾‹")
            return []

        self.log(f"å¼€å§‹æ–‡ç”Ÿå›¾æµ‹è¯•ï¼Œå…± {len(cases)} ä¸ªæ¡ˆä¾‹ï¼Œä½¿ç”¨æ¨¡å‹: {self.image_model}")
        self.image_stats = TestStats()
        self.image_stats.total_cases = len(cases)
        test_start_time = time.time()
        results = []
        failed_cases = []

        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            futures = {}
            for case in cases:
                if not self.is_running:
                    break
                future = executor.submit(self.run_single_image_test, case)
                futures[future] = case

            for i, future in enumerate(as_completed(futures)):
                if not self.is_running:
                    break
                case = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                    self.image_stats.success_count += 1

                    # ç»Ÿè®¡tokens
                    if "token_usage" in result:
                        self.image_stats.total_tokens.add(result["token_usage"])

                    # ç´¯åŠ å•caseå®é™…è€—æ—¶
                    case_duration = result.get("duration_seconds", 0)
                    self.image_stats.sum_case_time_seconds += case_duration

                    # ç»Ÿè®¡å›¾ç‰‡æå–æƒ…å†µ
                    if result.get("has_image"):
                        self.image_stats.html_extracted_count += 1  # å¤ç”¨å­—æ®µè¡¨ç¤ºå›¾ç‰‡æå–æˆåŠŸ
                    else:
                        self.image_stats.no_html_count += 1

                    # ç»Ÿè®¡é‡è¯•æ¬¡æ•°
                    self.image_stats.retry_count += result.get("retry_count", 0)

                    # ç»Ÿè®¡ä¸å®Œæ•´å“åº”
                    if result.get("is_incomplete"):
                        self.image_stats.incomplete_count += 1

                    self.log(f"âœ… [æ–‡ç”Ÿå›¾] {case['id']} {case['name']} - æˆåŠŸ (è€—æ—¶{case_duration}ç§’, {result.get('tokens_per_second', 0):.1f} tok/s)")
                except Exception as e:
                    error_msg = str(e)
                    self.image_stats.failed_count += 1

                    # æ£€æµ‹æ˜¯å¦ä¸ºè¶…æ—¶é”™è¯¯
                    if "è¶…æ—¶" in error_msg or "timeout" in error_msg.lower():
                        self.image_stats.timeout_count += 1

                    self.log(f"âŒ [æ–‡ç”Ÿå›¾] {case['id']} {case['name']} - å¤±è´¥: {error_msg}")
                    failed_result = {
                        "id": case["id"],
                        "name": case["name"],
                        "category": case.get("category", "æœªåˆ†ç±»"),
                        "difficulty": case.get("difficulty", "ä¸­"),
                        "tags": case.get("tags", []),
                        "icon": case.get("icon", "ğŸ–¼ï¸"),
                        "prompt": case["prompt"],
                        "success": False,
                        "error": error_msg,
                        "timestamp": datetime.now().isoformat()
                    }
                    results.append(failed_result)
                    failed_cases.append(case)

                progress = 50 + (i + 1) / len(cases) * 50
                self.update_progress(progress)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.image_stats.total_time_seconds = time.time() - test_start_time
        if self.image_stats.success_count > 0:
            # ä½¿ç”¨å•caseå®é™…è€—æ—¶æ€»å’Œè®¡ç®—å¹³å‡å€¼
            self.image_stats.avg_time_per_case = self.image_stats.sum_case_time_seconds / self.image_stats.success_count
            # è®¡ç®—å¹³å‡è¾“å‡ºtokens
            self.image_stats.avg_output_tokens_per_case = self.image_stats.total_tokens.completion_tokens / self.image_stats.success_count
            # è®¡ç®—å¹³å‡è¾“å‡ºé€Ÿç‡
            if self.image_stats.sum_case_time_seconds > 0:
                self.image_stats.avg_tokens_per_second = self.image_stats.total_tokens.completion_tokens / self.image_stats.sum_case_time_seconds

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        self.log(f"ğŸ“Š æ–‡ç”Ÿå›¾æµ‹è¯•å®Œæˆ:")
        self.log(f"    æˆåŠŸ: {self.image_stats.success_count}/{self.image_stats.total_cases}")
        self.log(f"    å›¾ç‰‡æå–: {self.image_stats.html_extracted_count}, æœªæå–: {self.image_stats.no_html_count}")
        self.log(f"    æ€»Tokens: {self.image_stats.total_tokens.total_tokens} (è¾“å…¥: {self.image_stats.total_tokens.prompt_tokens}, è¾“å‡º: {self.image_stats.total_tokens.completion_tokens})")
        self.log(f"    å¤šçº¿ç¨‹æ€»è€—æ—¶: {self.image_stats.total_time_seconds:.1f}ç§’")
        self.log(f"    å•caseå¹³å‡è€—æ—¶: {self.image_stats.avg_time_per_case:.1f}ç§’ (åŸºäº{self.image_stats.success_count}ä¸ªæˆåŠŸæ¡ˆä¾‹)")
        self.log(f"    å•caseå¹³å‡è¾“å‡º: {self.image_stats.avg_output_tokens_per_case:.0f} tokens")
        self.log(f"    å¹³å‡è¾“å‡ºé€Ÿç‡: {self.image_stats.avg_tokens_per_second:.1f} tokens/s")
        if self.image_stats.timeout_count > 0:
            self.log(f"    â° è¶…æ—¶æ¬¡æ•°: {self.image_stats.timeout_count}")
        if self.image_stats.retry_count > 0:
            self.log(f"    ğŸ”„ é‡è¯•æ¬¡æ•°: {self.image_stats.retry_count}")
        if self.image_stats.incomplete_count > 0:
            self.log(f"    âš ï¸ ä¸å®Œæ•´å“åº”: {self.image_stats.incomplete_count}")

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = self.output_dir / "image" / "_stats.json"
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(self.image_stats.to_dict(), f, ensure_ascii=False, indent=2)

        self.results["image"] = results
        return results

    def run_single_image_test(self, case) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ–‡ç”Ÿå›¾æµ‹è¯•ï¼ˆå¸¦é‡è¯•ï¼‰"""
        api_result = self.call_api_with_retry(
            case["prompt"],
            self.image_model,
            is_image=True,
            case_id=case["id"]
        )

        response_json = api_result["response"]
        token_usage = api_result["token_usage"]
        duration_seconds = api_result["duration_seconds"]
        retry_count = api_result["retry_count"]
        tokens_per_second = api_result.get("tokens_per_second", 0)
        is_incomplete = api_result.get("is_incomplete", False)
        finish_reason = api_result.get("finish_reason", "")

        # å®‰å…¨æå–å†…å®¹ - æ”¯æŒå¤šç§å“åº”æ ¼å¼
        content = ""
        reasoning_content = ""
        raw_response = ""

        try:
            message = response_json.get("choices", [{}])[0].get("message", {})

            # å°è¯•è·å–å¸¸è§„content
            content = message.get("content") or ""

            # å°è¯•è·å–reasoning_content (deepseek-reasonerç­‰æ¨ç†æ¨¡å‹)
            reasoning_content = message.get("reasoning_content") or ""

            # å¦‚æœcontentä¸ºç©ºä½†reasoning_contentæœ‰å†…å®¹ï¼Œä½¿ç”¨reasoning_content
            if not content and reasoning_content:
                content = reasoning_content
                self.log(f"    ğŸ“ [{case['id']}] ä½¿ç”¨reasoning_contentä½œä¸ºå“åº”å†…å®¹")

            # å¦‚æœä¸¤è€…éƒ½ä¸ºç©ºï¼Œä¿å­˜å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
            if not content and not reasoning_content:
                raw_response = json.dumps(response_json, ensure_ascii=False, indent=2)
                self.log(f"    âš ï¸ [{case['id']}] contentå’Œreasoning_contentå‡ä¸ºç©ºï¼Œä¿å­˜åŸå§‹å“åº”")
                content = raw_response

        except (KeyError, IndexError, TypeError) as e:
            self.log(f"    âš ï¸ [{case['id']}] å“åº”æ ¼å¼å¼‚å¸¸: {str(e)}")
            raw_response = json.dumps(response_json, ensure_ascii=False, indent=2)
            content = raw_response

        # æå–å¹¶ä¿å­˜å›¾ç‰‡ï¼ˆæ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼‰
        safe_name = sanitize_filename(case["name"])
        image_path = self.extract_and_save_image(content, case["id"], safe_name)

        # ä¿å­˜å“åº”
        output_file = self.output_dir / "image" / f"{case['id']}_{safe_name}.json"
        clean_content = self.remove_base64_from_content(content)

        result = {
            "id": case["id"],
            "name": case["name"],
            "category": case.get("category", "æœªåˆ†ç±»"),
            "difficulty": case.get("difficulty", "ä¸­"),
            "tags": case.get("tags", []),
            "icon": case.get("icon", "ğŸ–¼ï¸"),
            "prompt": case["prompt"],
            "response": clean_content,
            "reasoning_content": reasoning_content[:500] + "..." if len(reasoning_content) > 500 else reasoning_content if reasoning_content else None,
            "has_image": image_path is not None,
            "timestamp": datetime.now().isoformat(),
            "success": True,
            # æ–°å¢å­—æ®µ
            "token_usage": asdict(token_usage),
            "duration_seconds": duration_seconds,
            "retry_count": retry_count,
            "tokens_per_second": tokens_per_second,
            "is_incomplete": is_incomplete,
            "finish_reason": finish_reason,
            "model": self.image_model
        }

        if image_path:
            result["image_file"] = str(image_path)
        else:
            # å¦‚æœæ²¡æœ‰æå–åˆ°å›¾ç‰‡ï¼Œä¿å­˜åŸå§‹å“åº”åˆ°txtæ–‡ä»¶
            txt_file = self.output_dir / "image" / f"{case['id']}_{safe_name}_raw.txt"
            with open(txt_file, "w", encoding="utf-8") as f:
                f.write(content if content else raw_response if raw_response else "å“åº”ä¸ºç©º")
            result["txt_file"] = str(txt_file)
            self.log(f"    âš ï¸ [{case['id']}] æœªèƒ½æå–å›¾ç‰‡ï¼ŒåŸå§‹å“åº”å·²ä¿å­˜åˆ° {txt_file.name}")

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # è¿”å›token_usageå¯¹è±¡ä¾›ç»Ÿè®¡ä½¿ç”¨
        result["token_usage"] = token_usage
        return result

    def remove_base64_from_content(self, content):
        """ä»å†…å®¹ä¸­ç§»é™¤base64æ•°æ®"""
        patterns = [
            r'(data:image/(?:jpeg|png|jpg);base64,)[A-Za-z0-9+/=]{100,}',
        ]

        clean_content = content
        for pattern in patterns:
            clean_content = re.sub(pattern, r'\1[å›¾ç‰‡æ•°æ®å·²ç§»é™¤]', clean_content)

        return clean_content

    def extract_and_save_image(self, content, case_id, case_name):
        """æå–å¹¶ä¿å­˜base64å›¾ç‰‡"""
        patterns = [
            r'data:image/(jpeg|png|jpg);base64,([A-Za-z0-9+/=]+)',
            r'!\[.*?\]\(data:image/(jpeg|png|jpg);base64,([A-Za-z0-9+/=]+)\)',
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                if len(match.groups()) == 2:
                    img_format, img_data = match.groups()
                else:
                    img_format = "png"
                    img_data = match.group(1)

                try:
                    img_bytes = base64.b64decode(img_data)
                    ext = "jpg" if img_format == "jpeg" else img_format
                    img_path = self.output_dir / "image" / f"{case_id}_{case_name}.{ext}"

                    with open(img_path, "wb") as f:
                        f.write(img_bytes)
                    return img_path
                except Exception as e:
                    self.log(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {str(e)}")

        return None

    def run_writing_tests(self):
        """æ‰§è¡Œæ–‡ç”Ÿæ–‡ï¼ˆå†™ä½œèƒ½åŠ›ï¼‰æµ‹è¯•"""
        cases = self.load_test_cases("writing")
        if not cases:
            self.log("æœªæ‰¾åˆ°æ–‡ç”Ÿæ–‡æµ‹è¯•ç”¨ä¾‹")
            return []

        self.log(f"å¼€å§‹æ–‡ç”Ÿæ–‡æµ‹è¯•ï¼Œå…± {len(cases)} ä¸ªæ¡ˆä¾‹ï¼Œä½¿ç”¨æ¨¡å‹: {self.text_model}")
        self.writing_stats = TestStats()
        self.writing_stats.total_cases = len(cases)
        test_start_time = time.time()
        results = []

        # è®°å½•å¤±è´¥çš„æ¡ˆä¾‹
        failed_cases = []

        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            futures = {}
            for case in cases:
                if not self.is_running:
                    break
                future = executor.submit(self.run_single_writing_test, case)
                futures[future] = case

            for i, future in enumerate(as_completed(futures)):
                if not self.is_running:
                    break
                case = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                    self.writing_stats.success_count += 1

                    # ç»Ÿè®¡tokens
                    if "token_usage" in result:
                        self.writing_stats.total_tokens.add(result["token_usage"])

                    # ç´¯åŠ å•caseå®é™…è€—æ—¶
                    case_duration = result.get("duration_seconds", 0)
                    self.writing_stats.sum_case_time_seconds += case_duration

                    # ç»Ÿè®¡é‡è¯•æ¬¡æ•°
                    self.writing_stats.retry_count += result.get("retry_count", 0)

                    # ç»Ÿè®¡ä¸å®Œæ•´å“åº”
                    if result.get("is_incomplete"):
                        self.writing_stats.incomplete_count += 1

                    self.log(f"âœ… [æ–‡ç”Ÿæ–‡] {case['id']} {case['name']} - æˆåŠŸ (è€—æ—¶{case_duration}ç§’, {result.get('tokens_per_second', 0):.1f} tok/s)")
                except Exception as e:
                    error_msg = str(e)
                    self.writing_stats.failed_count += 1

                    # æ£€æµ‹æ˜¯å¦ä¸ºè¶…æ—¶é”™è¯¯
                    if "è¶…æ—¶" in error_msg or "timeout" in error_msg.lower():
                        self.writing_stats.timeout_count += 1

                    self.log(f"âŒ [æ–‡ç”Ÿæ–‡] {case['id']} {case['name']} - å¤±è´¥: {error_msg}")
                    failed_result = {
                        "id": case["id"],
                        "name": case["name"],
                        "category": case.get("category", "æœªåˆ†ç±»"),
                        "difficulty": case.get("difficulty", "ä¸­"),
                        "tags": case.get("tags", []),
                        "icon": case.get("icon", "ğŸ“"),
                        "prompt": case["prompt"],
                        "success": False,
                        "error": error_msg,
                        "timestamp": datetime.now().isoformat()
                    }
                    results.append(failed_result)
                    failed_cases.append(case)

                progress = (i + 1) / len(cases) * 100
                self.update_progress(progress)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.writing_stats.total_time_seconds = time.time() - test_start_time
        if self.writing_stats.success_count > 0:
            self.writing_stats.avg_time_per_case = self.writing_stats.sum_case_time_seconds / self.writing_stats.success_count
            self.writing_stats.avg_output_tokens_per_case = self.writing_stats.total_tokens.completion_tokens / self.writing_stats.success_count
            if self.writing_stats.sum_case_time_seconds > 0:
                self.writing_stats.avg_tokens_per_second = self.writing_stats.total_tokens.completion_tokens / self.writing_stats.sum_case_time_seconds

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        self.log(f"ğŸ“Š æ–‡ç”Ÿæ–‡æµ‹è¯•å®Œæˆ:")
        self.log(f"    æˆåŠŸ: {self.writing_stats.success_count}/{self.writing_stats.total_cases}")
        self.log(f"    æ€»Tokens: {self.writing_stats.total_tokens.total_tokens} (è¾“å…¥: {self.writing_stats.total_tokens.prompt_tokens}, è¾“å‡º: {self.writing_stats.total_tokens.completion_tokens})")
        self.log(f"    å¤šçº¿ç¨‹æ€»è€—æ—¶: {self.writing_stats.total_time_seconds:.1f}ç§’")
        self.log(f"    å•caseå¹³å‡è€—æ—¶: {self.writing_stats.avg_time_per_case:.1f}ç§’")
        self.log(f"    å•caseå¹³å‡è¾“å‡º: {self.writing_stats.avg_output_tokens_per_case:.0f} tokens")
        self.log(f"    å¹³å‡è¾“å‡ºé€Ÿç‡: {self.writing_stats.avg_tokens_per_second:.1f} tokens/s")
        if self.writing_stats.timeout_count > 0:
            self.log(f"    â° è¶…æ—¶æ¬¡æ•°: {self.writing_stats.timeout_count}")
        if self.writing_stats.retry_count > 0:
            self.log(f"    ğŸ”„ é‡è¯•æ¬¡æ•°: {self.writing_stats.retry_count}")
        if self.writing_stats.incomplete_count > 0:
            self.log(f"    âš ï¸ ä¸å®Œæ•´å“åº”: {self.writing_stats.incomplete_count}")

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = self.output_dir / "writing" / "_stats.json"
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(self.writing_stats.to_dict(), f, ensure_ascii=False, indent=2)

        self.results["writing"] = results
        return results

    def run_single_writing_test(self, case) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ–‡ç”Ÿæ–‡ï¼ˆå†™ä½œèƒ½åŠ›ï¼‰æµ‹è¯•"""
        api_result = self.call_api_with_retry(
            case["prompt"],
            self.text_model,
            is_image=False,
            case_id=case["id"]
        )

        response_json = api_result["response"]
        token_usage = api_result["token_usage"]
        duration_seconds = api_result["duration_seconds"]
        retry_count = api_result["retry_count"]
        tokens_per_second = api_result.get("tokens_per_second", 0)
        is_incomplete = api_result.get("is_incomplete", False)
        finish_reason = api_result.get("finish_reason", "")

        # å®‰å…¨æå–å†…å®¹
        content = ""
        reasoning_content = ""

        try:
            message = response_json.get("choices", [{}])[0].get("message", {})
            content = message.get("content") or ""
            reasoning_content = message.get("reasoning_content") or ""

            if not content and reasoning_content:
                content = reasoning_content
                self.log(f"    ğŸ“ [{case['id']}] ä½¿ç”¨reasoning_contentä½œä¸ºå“åº”å†…å®¹")

        except (KeyError, IndexError, TypeError) as e:
            self.log(f"    âš ï¸ [{case['id']}] å“åº”æ ¼å¼å¼‚å¸¸: {str(e)}")
            content = json.dumps(response_json, ensure_ascii=False, indent=2)

        # ä¿å­˜å“åº”ï¼ˆæ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼‰
        safe_name = sanitize_filename(case['name'])
        output_file = self.output_dir / "writing" / f"{case['id']}_{safe_name}.json"
        result = {
            "id": case["id"],
            "name": case["name"],
            "category": case.get("category", "æœªåˆ†ç±»"),
            "difficulty": case.get("difficulty", "ä¸­"),
            "tags": case.get("tags", []),
            "icon": case.get("icon", "ğŸ“"),
            "prompt": case["prompt"],
            "response": content,
            "reasoning_content": reasoning_content if reasoning_content else None,
            "timestamp": datetime.now().isoformat(),
            "success": True,
            "token_usage": asdict(token_usage),
            "duration_seconds": duration_seconds,
            "retry_count": retry_count,
            "tokens_per_second": tokens_per_second,
            "is_incomplete": is_incomplete,
            "finish_reason": finish_reason,
            "model": self.text_model
        }

        # è®¡ç®—å­—æ•°ç»Ÿè®¡
        result["char_count"] = len(content)
        result["word_count"] = len(content.split())

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # åŒæ—¶ä¿å­˜çº¯æ–‡æœ¬æ–‡ä»¶ä¾¿äºæŸ¥çœ‹
        txt_file = self.output_dir / "writing" / f"{case['id']}_{safe_name}.txt"
        with open(txt_file, "w", encoding="utf-8") as f:
            f.write(f"=== {case['name']} ===\n\n")
            f.write(f"ã€æç¤ºè¯ã€‘\n{case['prompt']}\n\n")
            f.write(f"ã€æ¨¡å‹å“åº”ã€‘\n{content}\n")

        result["txt_file"] = str(txt_file)
        result["token_usage"] = token_usage
        return result

    def retry_failed_tests(self, test_type="all"):
        """
        é‡è¯•å¤±è´¥çš„æµ‹è¯•æ¡ˆä¾‹

        Args:
            test_type: "text", "image", æˆ– "all"
        """
        retry_count = 0

        if test_type in ["text", "all"]:
            failed_text = [r for r in self.results.get("text", []) if not r.get("success", True)]
            if failed_text:
                self.log(f"ğŸ”„ é‡è¯• {len(failed_text)} ä¸ªå¤±è´¥çš„ä»£ç ç”Ÿæˆæ¡ˆä¾‹...")
                for result in failed_text:
                    case = {
                        "id": result["id"],
                        "name": result["name"],
                        "category": result.get("category", "æœªåˆ†ç±»"),
                        "difficulty": result.get("difficulty", "ä¸­"),
                        "tags": result.get("tags", []),
                        "icon": result.get("icon", "ğŸ“„"),
                        "prompt": result["prompt"]
                    }
                    try:
                        new_result = self.run_single_text_test(case)
                        # æ›´æ–°ç»“æœ
                        idx = next(i for i, r in enumerate(self.results["text"]) if r["id"] == case["id"])
                        self.results["text"][idx] = new_result
                        self.log(f"âœ… [é‡è¯•æˆåŠŸ] {case['id']} {case['name']}")
                        retry_count += 1
                    except Exception as e:
                        self.log(f"âŒ [é‡è¯•å¤±è´¥] {case['id']} {case['name']}: {str(e)}")

        if test_type in ["image", "all"]:
            failed_image = [r for r in self.results.get("image", []) if not r.get("success", True)]
            if failed_image:
                self.log(f"ğŸ”„ é‡è¯• {len(failed_image)} ä¸ªå¤±è´¥çš„æ–‡ç”Ÿå›¾æ¡ˆä¾‹...")
                for result in failed_image:
                    case = {
                        "id": result["id"],
                        "name": result["name"],
                        "category": result.get("category", "æœªåˆ†ç±»"),
                        "difficulty": result.get("difficulty", "ä¸­"),
                        "tags": result.get("tags", []),
                        "icon": result.get("icon", "ğŸ–¼ï¸"),
                        "prompt": result["prompt"]
                    }
                    try:
                        new_result = self.run_single_image_test(case)
                        idx = next(i for i, r in enumerate(self.results["image"]) if r["id"] == case["id"])
                        self.results["image"][idx] = new_result
                        self.log(f"âœ… [é‡è¯•æˆåŠŸ] {case['id']} {case['name']}")
                        retry_count += 1
                    except Exception as e:
                        self.log(f"âŒ [é‡è¯•å¤±è´¥] {case['id']} {case['name']}: {str(e)}")

        return retry_count

    def save_summary_stats(self):
        """ä¿å­˜æ€»ä½“ç»Ÿè®¡æ‘˜è¦"""
        self.end_time = time.time()
        summary = self.get_stats_summary()
        summary["timestamp"] = datetime.now().isoformat()
        summary["config"] = {
            "api_url": self.api_url,
            "text_model": self.text_model,
            "image_model": self.image_model,
            "max_threads": self.max_threads
        }

        stats_file = self.output_dir / "_summary_stats.json"
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        self.log(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡å·²ä¿å­˜åˆ° {stats_file.name}")
        return summary

    def run_all_tests(self):
        """æ‰§è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ä¿å­˜ç»Ÿè®¡"""
        self.start_time = time.time()

        self.log("=" * 50)
        self.log("å¼€å§‹AIæ¨¡å‹æµ‹è¯„")
        self.log("=" * 50)

        # æ‰§è¡Œä»£ç ç”Ÿæˆæµ‹è¯•
        self.run_text_tests()

        # æ‰§è¡Œæ–‡ç”Ÿå›¾æµ‹è¯•
        self.run_image_tests()

        # ä¿å­˜æ€»ä½“ç»Ÿè®¡
        summary = self.save_summary_stats()

        self.log("=" * 50)
        self.log("æµ‹è¯„å®Œæˆ!")
        self.log(f"æ€»è€—æ—¶: {summary['total_time_seconds']}ç§’")
        self.log(f"æ€»Tokens: {summary['total_tokens']['total_tokens']}")
        self.log("=" * 50)

        return self.results
